function [y,p,ip,crb,pse,xp,a,ia,psi,xsr] = mof(x,z,nord,maxord,sig2,auto,lplot,ivar,bvar,maxopt)
%
%  MOF  Identifies multivariate polynomial models from measured data using orthogonal functions.  
%
%  Usage: [y,p,ip,crb,pse,xp,a,ia,psi] = mof(x,z,nord,maxord,sig2,auto,lplot,ivar,bvar,maxopt);
%
%  Description:
%
%    Identifies polynomial models from measured input-output data 
%    using multivariate orthogonal functions generated by 
%    Gram-Schmidt orthogonalization, ordered by dynamic programming.  
%
%  Input:
%
%        x = matrix of independent variable vectors.
%        z = dependent variable vector.
%     nord = vector of maximum independent variable orders.
%   maxord = maximum order of each model term.
%     sig2 = dependent variable noise variance (optional)
%            =  0 or omit this input for the default value.
%            = -1 to use a linear model fit to estimate sig2.
%            =  a positive, independently-estimated noise variance.
%     auto = flag indicating type of operation (optional):
%            = 1 for automatic  (no user input required).
%            = 0 for manual  (user input required, default).
%    lplot = flag for model structure metric plots (optional):
%            = 1 for plots.
%            = 0 to skip the plots (default). 
%     ivar = x array column number of the independent variable
%            to be used for the orthogonal function generation seed (optional)
%            (use zero or omit this input for a constant function seed). 
%     bvar = x array column number of the independent variable
%            to be used for orthogonal blocking (optional)
%            (use zero or omit this input to skip orthogonal blocking). 
%   maxopt = maximum number of ordinary polynomial terms 
%            in the final model (optional).   
%
%  Output:
%
%       y = model output vector.
%       p = parameter vector for the ordinary polynomial function expansion.
%      ip = vector of integer indices for ordinary polynomial functions.
%     crb = estimated parameter covariance matrix.
%     pse = predicted squared error.  
%      xp = matrix of vector polynomial functions for the final model. 
%       a = parameter vector for the orthogonal function expansion.
%      ia = vector of integer indices for the orthogonal functions.
%     psi = matrix of vector orthogonal functions. 
%

%
%    Calls:
%      sclx.m
%      lesq.m
%      rms.m
%      reggen.m
%      gsorth.m
%      misvd.m
%      comfun.m
%
%    Author:  Eugene A. Morelli
%
%    History:  
%      20 Sept 2002 - Created and debugged, EAM.
%      11 Dec  2002 - Included orthogonal function re-ordering
%                     to minimize the number of final model terms, 
%                     added code to drop generated orthogonal functions 
%                     with small norms, EAM.
%      22 Dec  2002 - Added orthogonal blocking option, EAM.
%      22 Dec  2002 - Added maximum ordinary polynomial terms option, EAM.
%      07 Feb  2005 - Streamlined the code, added dynamic programming to
%                     order the orthogonal functions, EAM.
%      09 Feb  2005 - Raised lower limit for retaining ordinary polynomial
%                     functions in the final model to 0.5 percent, EAM.
%
%  Copyright (C) 2006  Eugene A. Morelli
%
%  This program carries no warranty, not even the implied 
%  warranty of merchantability or fitness for a particular purpose.  
%
%  Please email bug reports or suggestions for improvements to:
%
%      e.a.morelli@nasa.gov
%

%
%  Initialization.
%
if nargin < 10
  maxopt=0;
else
  maxopt=round(maxopt);
end
if nargin < 9
  bvar=0;
end
if nargin < 8
  ivar=0;
end
if nargin < 7
  lplot=0;
end
if nargin < 6
  auto=0;
end
if nargin < 5 
  sig2=0;
else
  if isempty(sig2)
    sig2=0;
  end
end
max_order=8;
max_ofcns=200;
z=z(:,1);
[npts,nvar]=size(x);
%
%  Separate the blocking variable, if necessary.
%
if (bvar <= nvar) & (bvar > 0)
  xb=x(:,bvar);
  xindx=find([1:nvar]'~=bvar);  
  x=x(:,xindx);
  if length(nord) > length(xindx)
    nord=nord(xindx);
  end
  nvar=length(xindx);
end
%
%  Scale the independent variables to prevent
%  numerical problems with the decomposition
%  of orthogonal functions into ordinary polynomial functions.
%
[xs,xsf]=sclx(x);
%
%  svlim = minimum singular value ratio for matrix inversion.
%  ztol = maximum absolute value considered different from zero.
%  pfztol = maximum absolute value for retaining polynomial function
%           components for each orthogonal function expansion.  
%
svlim=eps*npts;
ztol=1.0e-08;
pfztol=1.0e-08;
%
%  Open the output file.
%
[fid,message]=fopen('mof.out','w');
if fid < 3
  message,
  return
end
%
%  Check input variables nord and maxord.
%
if length(nord) ~= nvar
  fprintf(1,'\n  Incorrect length for input vector nord \n\n');
  fprintf(fid,'\n  Incorrect length for input vector nord \n\n');
  return
end
maxord=abs(maxord);
ksum=0;
for j=1:nvar,
  if nord(j) > max_order
    nord(j)=max_order;
  end
  ksum=ksum + nord(j);
end
if maxord > ksum
  maxord=ksum;
end
%
%  Record maxord and nord in the output file.
%
fprintf(fid,'\n\n Maximum order per term, maxord = %2.0f',maxord);
fprintf(fid,'\n\n Maximum order per variable, nord = [ %2.0f',nord(1));
for j=2:nvar,
  fprintf(fid,', %2.0f',nord(j));
end
fprintf(fid,' ] \n\n\n');
%
%  Assign a legal value to input variable ivar.
%
ivar=round(max(0,min(ivar,nvar)));
svlim=abs(svlim);
%
%  Compute quantities dependent on the measured output data.
%
zbar=mean(z);
z2=z'*z;
R2den=z2-npts*zbar*zbar;
zrms=rms(z);
if sig2==0
%
%  Default is to compute the maximum variance assuming
%  a constant model for z and a uniform error distribution.
%
  sig2max=(z-zbar*ones(npts,1))'*(z-zbar*ones(npts,1))/(2.0*npts);
  sig2=sig2max;
elseif sig2==-1
%
%  Compute the maximum variance assuming a linear 
%  model for z in terms of the independent variable
%  columns of x.  Make the maximum variance sig2max 
%  correspond to 2 times the estimated standard 
%  deviation, (2*sqrt(s2lin))^2.  The factor is 
%  only 2 here because any nonlinearity will inflate the 
%  value of s2lin.  Otherwise, the factor would be 5, 
%  as it is below for an independent estimate of sig2.
%
  [ylin,plin,cvarlin,s2lin]=lesq([ones(npts,1),xs],z);
  sig2max=2*2*s2lin;
  sig2=s2lin;
else
%
%  If sig2 is input, then make the maximum variance 
%  sig2max correspond to 5 times the estimated 
%  standard deviation, sig2max=(5*sqrt(sig2))^2.
%
  sig2max=5*5*sig2;
end
%
%  Orthogonal function generation.
%
%  First generate ordinary polynomial regressors.
%
[xsr,xslab,ip]=reggen(xs,nord,maxord,1);
ntf=size(xsr,2);
%
%  Include independent ivar to the first power 
%  in each term if ivar > 0.  
%
if ivar > 0
  xsr=xsr.*(xs(:,ivar)*ones(1,ntf));
  ip=ip+round(10^ivar)*ones(ntf,1);
end
%
%  Add the blocking variable to the first power, 
%  if a blocking variable was specified. 
%
if bvar > 0
  xsr=[xsr,xb];
  ip=[ip;10^nvar];
  ntf=ntf+1;
  xslab=[xslab;char(zeros(1,size(xslab,2)))];
  xslab(ntf,[1:5])='block';
end
%
%  Save the original ordinary polynomial regressors
%  and their labels.
%
xsro=xsr;
xslabo=xslab;
iao=ip;
%
%  Generate the orthogonal functions 
%  using the default order. 
%
ia=ip;
[psi,ao,m]=gsorth(xsr);
%[psi,ao]=qr(xsr);
%psi=psi(:,[1:ntf]);
%ao=ao([1:ntf],[1:ntf]);
%
%  Find orthogonal function parameter values.
%
p2=zeros(ntf,1);
a=zeros(ntf,1);
dmse=zeros(ntf,1);
nterms=[1:1:ntf]';
for n=1:ntf,
  p2(n)=psi(:,n)'*psi(:,n);
  a(n)=z'*psi(:,n)/p2(n);
  dmse(n)=-p2(n)*a(n)*a(n)/npts;
end
%
%  Drop out any orthogonal function with a norm
%  that is less than 0.01 percent of the output norm.  
%  This omits orthogonal functions that are 
%  numerically ill-conditioned, corresponding to 
%  columns of the original ordinary polynomial 
%  matrix xsr that are nearly linearly dependent
%  on other columns of xsr.  
%
kindx=find(p2/z2 > 0.0001);
dmse=dmse(kindx);
xsr=xsr(:,kindx);
xslab=xslab(kindx,:);
ia=ia(kindx);
psi=psi(:,kindx);
p2=p2(kindx);
a=a(kindx);
ntf=length(kindx);
%
%  Find the most effective orthogonal function.
%
%  Order the orthogonal functions from most to least 
%  effective in terms of reducing mean squared error.   
%
[dmse,sindx]=sort(dmse);
xsr=xsr(:,sindx);
xslab=xslab(sindx,:);
ia=ia(sindx);
%
%  Designate the ordinary regressor for   
%  the most effective orthogonal function 
%  as the first orthogonal function.
%
j=1;
psi(:,1)=xsr(:,1);
p2(1)=psi(:,1)'*psi(:,1);
a(1)=z'*psi(:,1)/p2(1);
dmse(1)=-p2(1)*a(1)*a(1)/npts;
%
%  Start of the orthogonal function regression 
%  to determine the best order for generating the 
%  orthogonal functions.  
%
while j<ntf-1,
  for k=j+1:ntf,
%
%  Orthogonalize the ordinary polynomial regressors 
%  one at a time, relative to the orthogonal functions 
%  already generated.  
%
    [xo,ao,m]=gsorth([psi(:,[1:j]),xsr(:,k)],j);
%    [xo,ao]=qr([xsr(:,[1:j]),xsr(:,k)]);
%    psi=psi(:,[1:j+1]);
%    ao=ao([1:j+1],[1:j+1]);
%
%  The last column of xo is the orthogonal 
%  function generated when xsr(:,k) is 
%  used as the next ordinary polynomial
%  orthogonalized with respect to psi(:,[1:j]).   
%
    psi(:,k)=xo(:,j+1);
%
%  Find orthogonal function quantities 
%  for each possible addition of a single orthogonal 
%  function, generated from each remaining ordinary 
%  polynomial function, one at a time.  
%
    p2(k)=psi(:,k)'*psi(:,k);
    a(k)=z'*psi(:,k)/p2(k);
    dmse(k)=-p2(k)*a(k)*a(k)/npts;
  end
%
%  Order the single added orthogonal functions 
%  from most to least effective in 
%  reducing the mean squared fit error.  
%  This procedure is a dynamic programming approach
%  to the sequential process of generating 
%  multivariate orthogonal modeling functions. 
%
%  The most effective single added orthogonal function 
%  will be in the j+1 spot.  
%
  [dmse(j+1:ntf),dindx]=sort(dmse(j+1:ntf));
  dindx=dindx+j;
  xsr(:,[j+1:ntf])=xsr(:,dindx);
  xslab([j+1:ntf],:)=xslab(dindx,:);
  ia(j+1:ntf)=ia(dindx);
%
%  Orthogonalize the remaining ordinary polynomials 
%  with respect to psi(:,[1:j]).  Then drop any 
%  ordinary polynomial whose corresponding orthogonal 
%  function has a small norm.  
%
  [psi,ao,m]=gsorth([psi(:,[1:j]),xsr(:,[j+1:ntf])],j);
%
%  Find orthogonal function parameter values.
%
  for n=1:ntf,
    p2(n)=psi(:,n)'*psi(:,n);
    a(n)=z'*psi(:,n)/p2(n);
    dmse(n)=-p2(n)*a(n)*a(n)/npts;
  end
%
%  Drop out any of the generated orthogonal 
%  functions with a norm less than 0.01 percent
%  of the output norm.  This omits orthogonal functions 
%  that are numerically ill-conditioned, corresponding 
%  to columns of the original ordinary polynomial 
%  matrix xsr that are nearly linearly dependent
%  on other columns of xsr.  
%
  kindx=find(p2/z2 > 0.0001);
  dmse=dmse(kindx);
  xsr=xsr(:,kindx);
  xslab=xslab(kindx,:);
  ia=ia(kindx);
  psi=psi(:,kindx);
  p2=p2(kindx);
  a=a(kindx);
  ntf=length(kindx);
%
%  Incrementing j includes the most effective of the 
%  newly-generated orthogonal functions.
%
  j=j+1;
end
%
%  Now re-generate the orthogonal functions. 
%  This is done so that the most effective
%  orthogonal functions are generated and 
%  considered for the model first, which 
%  results in better modeling accuracy with fewer 
%  multivariate polynomial functions in the final model.  
%
%  Generate the re-ordered orthogonal functions. 
%
nterms=[1:ntf]';
ip=ia;
[psi,ao,m]=gsorth(xsr);
%
%  Find orthogonal function parameter values.
%
p2=zeros(ntf,1);
a=zeros(ntf,1);
dmse=zeros(ntf,1);
for n=1:ntf,
  p2(n)=psi(:,n)'*psi(:,n);
  a(n)=z'*psi(:,n)/p2(n);
  dmse(n)=-p2(n)*a(n)*a(n)/npts;
end
sindx=nterms;
%
%  Compute mean squared error and 
%  predicted squared error for each 
%  orthogonal function added to the model.  
%
mse=zeros(ntf,1);
pse=zeros(ntf,1);
dpse=zeros(ntf,1);
y=psi(:,1)*a(1);
mse(1)=(z-y)'*(z-y)/npts;
pse(1)=mse(1)+2*sig2max*1/npts;
dpse(1)=dmse(1)+2*sig2max*1/npts;
for j=1:ntf-1,
  for k=j+1:ntf,
    if nterms(k) >= max(nterms(1:j))
      pse(k)=mse(j) + dmse(k) + 2*sig2max*nterms(k)/npts;
    else
      pse(k)=mse(j) + dmse(k) + 2*sig2max*max(nterms(1:j))/npts;
    end
  end
  [pse(j+1:ntf),dindx]=sort(pse(j+1:ntf));
  dindx=dindx+j;
  dmse(j+1:ntf)=dmse(dindx);
  mse(j+1)=mse(j)+dmse(j+1);
  nterms(j+1:ntf)=nterms(dindx);
  dpse(j)=dmse(j) +2*sig2max*nterms(j)/npts;
end
%
%
%  The original regressors are computed from:
%
%    xsr = xo*(ao+eye(ntf,ntf))';
%
%  so the decomposition of the orthogonal functions
%  in the columns of xo is given by:
%
%    xo = xsr*misvd((ao+eye(ntf,ntf))');
%
%  Defining ap=misvd((ao+eye(ntf,ntf))'),
%
%    xo = xsr*ap;
%
ap=misvd((ao+eye(ntf,ntf))');
%
%  Since the the columns of the xsr matrix 
%  have not been shuffled according to sindx, 
%  re-ordering the columns of ap will keep
%  the exact analytical decomposition of the 
%  orthogonal functions into the scaled 
%  polynomial regressors intact.  
%
ap=ap(:,sindx);
%
%  Check for generated functions that are not orthogonal.  This
%  usually indicates a problem related to information content of the data.
%  Variable nnof contains a count of non-orthogonal function pairs, and 
%  variable m contains the number of orthogonal functions generated
%  before a non-orthogonal function is encountered.  The number of 
%  orthogonal functions chosen for the model should be less than m
%  to avoid violating the theory underlying the modeling process
%  using multivariate orthogonal functions.    
%
ptp=psi'*psi;
nnof=0;
m=ntf;
for i=1:ntf-1,
  for j=i+1:ntf,
    if ptp(i,j) > ztol
%      fprintf(fid,'\n non-orthogonal measure: ');
%      fprintf(fid,'ptp(%3.0f ,%3.0f ) = %13.6e \n',i,j,ptp(i,j));
      if j <= m
        m=j-1;
      end
      nnof=nnof+1;
    end
  end
end
%
%  Print out guidance for orthogonal function selection to the analyst.
%
fprintf(1,'\n\n Dependent variable rms value = %12.4e \n',zrms);
fprintf(1,'\n Number of non-orthogonal function pairs = %4.0f \n',nnof);
fprintf(1,'\n Orthogonality intact through function number %4.0f \n\n',m);
fprintf(fid,'\n\n Dependent variable rms value = %4.0f \n',zrms);
fprintf(fid,'\n Number of non-orthogonal function pairs = %4.0f \n',nnof);
fprintf(fid,'\n Orthogonality intact through function number %4.0f \n\n',m);
%
%  Limit the number of orthogonal functions to those that 
%  satisfy the orthogonality criterion that their 
%  pairwise inner products are less than or equal to ztol.
%
ia=ia(1:m);
psi=psi(:,[1:m]);
p2=p2(1:m);
a=a(1:m);
ap=ap(:,[1:m]);
nterms=nterms(1:m);
ntf=m;
sindx=sindx(1:m);
dmse=dmse(1:m);
mse=mse(1:m);
pse=pse(1:m);
%
%  Implement the maximum number of ordinary polynomial
%  terms in the final model.  
%
if maxopt > 0
  indx=find(nterms <= maxopt);
  ia=ia(indx);
  psi=psi(:,indx);
  p2=p2(indx);
  a=a(indx);
  ap=ap(:,indx);
  nterms=nterms(indx);
  ntf=length(indx);
  sindx=sindx(indx);
  dmse=dmse(indx);
  mse=mse(indx);
  pse=pse(indx);
end
%
%  Orthogonal function selection for the model.  
%
R2=zeros(ntf,1);
fprintf(1,'\n o.f. #     index     sqrt(mse) ');
fprintf(1,'       dmse       perr      R2        pe         n       F');
fprintf(1,'\n ------     -----     --------- ');
fprintf(1,'       ----       ----      --        --         -       -');
fprintf(fid,'\n o.f. #     index     sqrt(mse) ');
fprintf(fid,'       dmse       perr      R2        pe         n       F');
fprintf(fid,'\n ------     -----     --------- ');
fprintf(fid,'       ----       ----      --        --         -       -');
for j=1:ntf,
  y=psi(:,[1:j])*a(1:j);
  R2(j)=100*(y'*z-npts*zbar*zbar)/R2den;
  fprintf(1,'\n  %3.0f    %8.0f',j,ia(j));
  fprintf(fid,'\n  %3.0f    %8.0f',j,ia(j));
  if dmse(j)>=0.0,
    fprintf(1,'    %10.3e     %10.3e   %5.2f    %5.2f   %10.3e   %3i    %6.2f',...
              sqrt(mse(j)),dmse(j),100*sqrt(mse(j))/zrms,R2(j),...
              sqrt(pse(j)),nterms(j),abs(dmse(j))*(npts/(npts-j))/sig2);
    fprintf(fid,'    %10.3e     %10.3e   %5.2f    %5.2f   %10.3e   %3i    %6.2f',...
              sqrt(mse(j)),dmse(j),100*sqrt(mse(j))/zrms,R2(j),...
              sqrt(pse(j)),nterms(j),abs(dmse(j))*(npts/(npts-j))/sig2);
  else
    fprintf(1,'    %10.3e    %10.3e   %5.2f    %5.2f   %10.3e   %3i    %6.2f',...
              sqrt(mse(j)),dmse(j),100*sqrt(mse(j))/zrms,R2(j),...
              sqrt(pse(j)),nterms(j),abs(dmse(j))*(npts/(npts-j))/sig2);
    fprintf(fid,'    %10.3e    %10.3e   %5.2f    %5.2f   %10.3e   %3i    %6.2f',...
              sqrt(mse(j)),dmse(j),100*sqrt(mse(j))/zrms,R2(j),...
              sqrt(pse(j)),nterms(j),abs(dmse(j))*(npts/(npts-j))/sig2);
  end
  if ((mod(j,20)==0) & (auto==0)),
    fprintf('\n\n');
    dummy=input('  more...        (type CR to continue) ');
    fprintf('\n');
  end
end
[minpse,jmin]=min(pse);
if lplot > 0
%
%  Set up the figure window.
%
  figure('Units','normalized',...
         'Position',[0.473 0.027 0.521 0.903],...
         'Color',[0.8 0.8 0.8],...
         'Name','Model Structure Determination',...
         'NumberTitle','off',...
         'ToolBar','none');
  subplot(2,1,1),
  plot([2:ntf]',sqrt(pse(2:ntf))),
  grid on;ylabel('Prediction Error'),
  hold on,subplot(2,1,1),
  plot(jmin,sqrt(minpse),'rd','MarkerSize',7,'MarkerFaceColor','r'),
  hold off;subplot(2,1,2),
  plot([2:ntf]',R2(2:ntf)),
  grid on;ylabel('R Squared'),xlabel('Number of Orthogonal Functions'),
  hold on;subplot(2,1,2),
  plot(jmin,R2(jmin),'rd','MarkerSize',7,'MarkerFaceColor','r'),
  hold off;
end
fprintf(1,'\n\n\n    Minimum pe at orthogonal function number %4.0f \n\n',...
          jmin);
fprintf(fid,'\n\n\n    Minimum pe at orthogonal function number %4.0f \n\n',...
            jmin);
nkf=jmin;
if auto==0,
  nkf=input(' Enter the number of orthogonal functions to keep ');
  if isempty(nkf)
    nkf=jmin;
  end
end
if nkf <= 0
  return
end
fprintf(fid,'\n\n Number of retained orthogonal functions is %4.0f \n\n',nkf);
R2=R2(nkf);
pse=pse(nkf);
y=psi(:,[1:nkf])*a(1:nkf);
sig2=((z-y)'*(z-y))/(npts-nkf);
fprintf(1,'\n\n For the %4.0f retained orthogonal functions: \n\n',nkf);
fprintf(fid,'\n\n For the %4.0f retained orthogonal functions: \n\n',nkf);
rmsd=sqrt((z-y)'*(z-y)/npts);
prmsd=100*rmsd/zrms;
fprintf(1,'   rms dev. = %11.4e      pct. error = %11.4e \n',rmsd,prmsd);
fprintf(fid,'   rms dev. = %11.4e      pct. error = %11.4e \n',rmsd,prmsd);
%
%  Break down each orthogonal function retained in the model
%  using ordinary polynomial terms and combine results.
%
npf=max(nterms(1:nkf));
%
%  Number of columns of ap equals the number of 
%  retained orthogonal functions.  Number of rows 
%  of ap equals the number of polynomial terms
%  in the final model.  Each column of ap 
%  is multiplied by the orthogonal function 
%  model parameter for the corresponding
%  retained orthogonal function.    
%
apo=ap([1:npf],[1:nkf]);
ap=apo*diag(a(1:nkf));
ps=sum(ap')';
ip=ip(1:npf);
ys=xsr(:,[1:npf])*ps;
%
%  Compute the Cramer-Rao bounds for the 
%  orthogonal function parameters a.
%
s2=(z-ys)'*(z-ys)/(npts-nkf);
crba=s2*diag(ones(nkf,1)./p2(1:nkf));
%
%  Now compute the Cramer-Rao bounds for 
%  the multivariate polynomial parameters, 
%  still using the scaled regressors.  
%
crb=(apo*sqrt(crba))*(apo*sqrt(crba))';
%
%  Loop for removing the scaling from each 
%  retained multivariate polynomial term.
%
xrsf=ones(npf,1);
for k=1:npf
  indx=ip(k);
  for j=1:nvar
    ji=round(rem(indx,10));
    if ji~=0
      xrsf(k)=xrsf(k)/(xsf(j)^ji);
    end
    indx=floor(indx/10);
  end
end
%
%  Adjust parameters using xrsf to get an expansion 
%  in terms of regressors using the original 
%  independent variable data.
%
p=ps.*xrsf;
xp=xsr(:,[1:npf])*diag(ones(npf,1)./xrsf);
crb=diag(xrsf)*crb*diag(xrsf);
%
%  Drop any terms that contribute less than 0.5 percent 
%  of the rms of the measured response.  
%
prms=ones(npf,1);
for j=1:npf,
  prms(j)=rms(p(j)*xp(:,j))/zrms;
end
indx=find(prms > 0.005);
p=p(indx);
ip=ip(indx);
crb=crb([indx],[indx]);
xp=xp(:,[indx']);
npf=length(p);
%
%  Polynomial regressors have been computed in xp, with 
%  associated parameters in p.  Now compute the model 
%  output for the final multivariate polynomial model.  
%
y=xp*p;
fprintf(1,'\n\n For the %4.0f retained polynomial functions: \n\n',npf);
fprintf(fid,'\n\n For the %4.0f retained polynomial functions: \n\n',npf);
rmsd=sqrt((z-y)'*(z-y)/npts);
prmsd=100*rmsd/zrms;
fprintf(1,'   rms dev. = %11.4e      pct. error = %11.4e \n',rmsd,prmsd);
fprintf(1,'\n\n');
fprintf(fid,'   rms dev. = %11.4e      pct. error = %11.4e \n',rmsd,prmsd);
fprintf(fid,'\n\n');
fclose(fid);
return
